ord_physums<-physums[rev(order(physums[,2])),]
sort_avgs<-data.frame(avgs$expgroup)
names(sort_avgs)[1]<-c("expgroup")
#loop is to sort by decreasing phyla and perform internal sort within phylum, return the new sorted avgs to go into mavgs
for(i in 1:numphyla){
val<-NULL
phy<-which(x %in% c(ord_physums[i,1])) #phy returns the indices for where that phyNum is
for(j in 1:length(phy)){ #using locations of phylum i to find in avgs
val[j]<-avgs[2,phy[j]+1]
}
phy<-phy[rev(order(val))]
for(j in 1:length(phy)){ #now loop through the sorted sub cols and add them to the sort_avgs
sort_avgs<-cbind(sort_avgs, avgs[,phy[j]+1])
names(sort_avgs)[length(sort_avgs)]<-names(avgs)[phy[j]+1]
}
}
attach(avgs)
sort_avgs<-cbind(sort_avgs, Other)
detach(avgs)
col <- c(1)
for( i in 2:(length(SEs)) ) {
col <- c(col, which(names(SEs)==names(sort_avgs)[i]))
}
sort_stderr <- SEs[,col]
sort_phy <- sort_avgs[1,]
sort_phy<-sort_phy[, -1]
sort_avgs <- sort_avgs[-1,] #get rid of phylum first row from earlier sorting
#loop for getting the right ids in the right order as sort
ids<-data.frame(1:(totalOTU))
row.names(sort_avgs)<-sort_avgs$expgroup
sort_avgs<-sort_avgs[,-1]
row.names(sort_stderr)<-sort_stderr$expgroup
sort_stderr<-sort_stderr[,-1]
for (i in 1:(length(sort_avgs)-1)){
found<-FALSE
#itime<-rbind(itime, i)
j<-1
while(found==FALSE){ #searching through ordIDS
test<-ordIDS[j, 1] == names(sort_avgs)[i]
if(test) {
ids[i,2]<-ordIDS[j, 3]
ids[i,3]<-ordIDS[j,2]
found<-TRUE
}
else{
j <- j + 1
#count<-count+1
#jtime<-rbind(jtime, j)
}
}
}
names(ids)<-c("x", "name", "phyname")
ids<-rbind(ids, data.frame(x=totalOTU+1, name= "Other", phyname="Other"))
ids<-cbind(ids, t(sort_phy))
names(ids)<-c("x", "name", "phyname", "phynum")
mavgs<-as.matrix(sort_avgs)
leng<-dim(mavgs)[2]
numgr <- length(unique(file$expgroup))
} ##end if(sortbyphyl == TRUE){
####order the results by the first group alpha numerically
if(sortbyphyl == FALSE){
row.names(avgs)<-avgs$expgroup
avgs<-avgs[,-1]
ordered_avgs<- avgs[, rev(order(avgs[1,1:length(avgs)-1]))] #sort all but other column (last)
attach(avgs)
ordered_avgs <- cbind(ordered_avgs, Other) #put other back on
detach(avgs)
mavgs<-as.matrix(ordered_avgs)
leng<-dim(mavgs)[2]
numgr <- length(unique(file$expgroup))
ids<-data.frame(1:(totalOTU))
for (i in 1:(length(ordered_avgs)-1)){
found<-FALSE
#itime<-rbind(itime, i)
j<-1
while(found==FALSE){ #searching through ordIDS
test<-ordIDS[j, 1] == names(ordered_avgs)[i]
if(test) {
ids[i,2]<-ordIDS[j, 3]
found<-TRUE
}
else{
j <- j + 1
#count<-count+1
#jtime<-rbind(jtime, j)
}
}
}
names(ids)<-c("x", "name")
ids<-rbind(ids, data.frame(x=totalOTU+1, name= "Other"))
}  #end if(sortbyphyl == FALSE){
###started to do the stds table... didnt complete
matrix.se<-as.matrix(sort_stderr)
#####################################################################################################################
#####################################################################################################################
#####################################################################################################################
###PLOT PARAMETERS
if(graphbyphyl==FALSE && divide==FALSE){
par(mfrow=c(numgr+1, 1)) #+1 to give extra labeling space
par(mar=c(0.3, 8, 0.5, 2) +0.1, mgp=c(4.5, 1, 0)) #default is 5.1 4.1 4.1 2.1, bot/left/top/right, also default mgp is c(3,1,0)
color_transparent <- adjustcolor("black", alpha.f = 0.1)
color <- gray.colors((numphyla+1), start=0, end=1, alpha=NULL)
count <- NULL
for (n in 1:(numphyla)){
count[n] <- length(which(ids$phynum==n))
}
colors <- NULL
for( n in 1:(length(color)-1) ) {
phyNumOrder <- unique(ids$phynum)
times <- count[phyNumOrder[n]]
temp <- rep( color[n], times )
colors <- c(colors, temp)
}
colors <- c(colors, "#FFFFFF")
for(j in 1:numgr){
if(j != numgr){
bp <- barplot(mavgs[j, 1:leng], ylab=NULL, col=colors,  yaxt="n", xaxt="n", ylim=c(0.001, 1), log="y", cex.names=3)
#error.bar(bp[k], mavgs[j, 1:leng[2]], mstds[j, 1:leng[2]])  #the bp[k] was for storing the barplot locations to use for these errors
# k <- k+1
d <- as.data.frame( cbind(bp, mavgs[j,], matrix.se[j,] ))
names(d) <- c("x", "y", "se")
with (
data = d
, expr = errbar(x, y, y+se, y-se, add=T, pch=".", cap=.01)
)
axis(2, las=1, at=c(.001, .01, .1, 1), labels=c(0, .01, .1, 1), cex.axis=1.1)
mtext(abx[j], side=2, line=6, cex=.8)
mtext(avgCD[j], side=2, line=4.5, cex=.8)
abline(h=c(0.001, 1), lwd=3) #min/max
abline(h=c(0.01, 0.1), col=color_transparent, lty="longdash", lwd=2)
abline(h=c(0.0025, 0.005, 0.0075, 0.025, 0.05, 0.075, 0.25, 0.5, 0.75), col=color_transparent, lty="dashed")
}
else{ #the last graph needs different margins
label<-barplot(mavgs[j, 1:leng], col=colors,ylab=NULL,  yaxt="n", xaxt="n", ylim=c(0.001, 1), log="y", cex.names=3)
d <- as.data.frame( cbind(label, mavgs[j,], matrix.se[j,] ))
names(d) <- c("x", "y", "se")
with (
data = d
, expr = errbar(x, y, y+se, y-se, add=T, pch=".", cap=.01)
)
#error.bar(bp[k], mavgs[j, 1:leng[2]], mstds[j, 1:leng[2]])  #the bp[k] was for storing the barplot locations to use for these errors
axis(2, las=1, at=c(.001, .01, .1, 1), labels=c(0, .01, .1, 1), cex.axis=1.1)
mtext(abx[j], side=2, line=6, cex=.8)
mtext(avgCD[j], side=2, line=4.5, cex=.8)
axis(1, at=(label[,1]), labels=FALSE)
text(label[,1]+.13, .0005, label=ids[,2], xpd=NA, pos=2, srt=45, cex=1.2)
#text(-3.9,.0001, label=expression(paste(italic("C.d."), " CFU/g Feces:")), xpd=NA, pos=2, srt=90, cex=1.1)
abline(h=c(0.001,1), lwd=3) #min/max
abline(h=c(0.01, 0.1), col=color_transparent, lty="longdash", lwd=2)
abline(h=c(0.0025, 0.005, 0.0075, 0.025, 0.05, 0.075, 0.25, 0.5, 0.75), col=color_transparent, lty="dashed")
}
}
par(mfrow=c(1, 1))
} #if(graphbyphyl=FALSE)
#####END 1ST PLOT PARAMETERS
################################
###2nd PLOT PARAMETERS
if(graphbyphyl==TRUE){
par(mfrow=c(numphyla+1, 1)) #+2 to give extra labeling space--numphyl doesn't include the Other group
#  par(mfrow=c(3, 1)) #temporarily for testing
par(mar=c(2.5, 8, 0.5, 2) +0.1, mgp=c(4.5, 1, 0)) #default is  par(mar=c(5, 4, 4, 2 ) +0.1, mgp=c(3, 1, 0)) bot/left/top/right, also default mgp is c(3,1,0)
colors= gray.colors(numgr, start=0, end=1, alpha=NULL)
currphy=ids[1, 4]
k <- 1
idleng<-dim(mavgs)[2]
j <- 1
while(j < (idleng+1)){
leng <- 0
while(currphy==ids[k, 4])
{
leng <- leng+1
k <- k+1
if( k > idleng ){
break}
}
label<-barplot(mavgs[,j:(leng+j-1)],, beside=TRUE, ylab=ids[j,3], col=colors, yaxt="n", xaxt="n", ylim=c(0.001, 1), log="y", cex.names=5)
#CTR+SHIFT+C=comment block of code out
#Will perform the pairwise wilcox test for each OTU and fill "statLetter" with the lettering scheme for the graph to show statistical signifiance
#This will work for the titration which has 3 different comparisons
statLetter <- NULL
statLetter <- matrix(c("NA"),nrow=numgr, ncol=leng)
otus <- dimnames(mavgs)[2][[1]][j:(leng+j-1)]
m <- j
for (i in 1:leng){
results.wilcox <- pairwise.wilcox.test(file[,which(names(file)==otus[i])], file$expgroup, p.adj="BH")
#results.wilcox <- pairwise.t.test(file[,which(names(file)==otus[i])], file$expgroup, p.adj="BH")
#double check that all values were calculated, if not put as n.s.
if(results.wilcox$p.value[1] == "NaN"){
results.wilcox$p.value[1] <- 10 #a value greater than 0.05
}
if(results.wilcox$p.value[2] == "NaN"){
results.wilcox$p.value[2] <- 10
}
if(results.wilcox$p.value[4] == "NaN"){
results.wilcox$p.value[4] <- 10
}
if( results.wilcox$p.value[1] >= 0.05 ){
if( results.wilcox$p.value[2] >= 0.05 ){
if( results.wilcox$p.value[4] >= 0.05 ){
statLetter[1, i] <- "a"
statLetter[2, i] <- "a"
statLetter[3, i] <- "a"
} else{
statLetter[1, i] <- "ab"
statLetter[2, i] <- "a"
statLetter[3, i] <- "b"
}
} else{
if( results.wilcox$p.value[4] >= 0.05 ){
statLetter[1, i] <- "a"
statLetter[2, i] <- "ab"
statLetter[3, i] <- "b"
} else{
statLetter[1, i] <- "a"
statLetter[2, i] <- "a"
statLetter[3, i] <- "b"
}
}
} else{
if( results.wilcox$p.value[2] >= 0.05 ){
if( results.wilcox$p.value[4] >= 0.05 ){
statLetter[1, i] <- "a"
statLetter[2, i] <- "b"
statLetter[3, i] <- "ab"
} else{
statLetter[1, i] <- "a"
statLetter[2, i] <- "b"
statLetter[3, i] <- "a"
}
} else{
if( results.wilcox$p.value[4] >= 0.05 ){
statLetter[1, i] <- "a"
statLetter[2, i] <- "b"
statLetter[3, i] <- "b"
} else{
statLetter[1, i] <- "a"
statLetter[2, i] <- "b"
statLetter[3, i] <- "c"
}
}
}
}
#For labeling letters above each bar
m <- j
for(n in 1:leng){
text( label[,n], mavgs[,m], labels=statLetter[,n], cex=1, col="red", pos=3, offset=0.15, xpd=TRUE)
m <- m+1
}
axis(2, las=1, at=c(.001, .01, .1, 1), labels=c(0, .01, .1, 1), cex.axis=1.1)
# mtext("Relative Abundance", side=2, line=6, cex=.8)
#mtext(avgCD[j], side=2, line=4.5, cex=.8)
abline(h=c(0.001, 1), lwd=3) #min/max
color_transparent <- adjustcolor("black", alpha.f = 0.1)
abline(h=c(0.01, 0.1), col=color_transparent, lty="longdash", lwd=2)
abline(h=c(0.0025, 0.005, 0.0075, 0.025, 0.05, 0.075, 0.25, 0.5, 0.75), col=color_transparent, lty="dashed")
labelAVG=apply(label, 2, mean)
axis(1, at=(labelAVG), labels=FALSE)
text(labelAVG+.13, .0005, label=ids[j:(leng+j-1),2], xpd=NA, pos=1, srt=15, cex=.8)
j<-j+leng
currphy <- ids[j, 4]
}
par(mfrow=c(1, 1))
} #if(graphbyphyl=TRUE)
################################
###3rd PLOT PARAMETERS
if(divide == TRUE){
mavgs <- mavgs[-which(grepl("untr", row.names(mavgs))),]
matrix.se <- matrix.se[-which(grepl("untr", row.names(matrix.se))),]
id.info <- id.info[-which(grepl("untr", id.info$expgroup)),]
barplotBeside(id.info = id.info, matrix.of.avgs = mavgs, matrix.of.se = matrix.se, ids = ids, file=file)
} # if(divide=TRUE){
}
###END 2ND PLOT PARAMETERS
##############END CODE###########################
#################################################
stackedbarcharts(file = "~/Documents/Github/abxD01/Figure 3/abxD01.final.tx2.subsample.alltitrations.forlogscale.csv", fileIDS = "~/Documents/Github/abxD01/Figure 3/alltitrations_tx2_barchart_ids.csv", divide = TRUE)
rf.results.perc5
data<-read.csv("~/Desktop/mothur/abxD01/model/abxD01.final.an.unique_list.0.03.subsample.shared.toptitdel.noNewUntr.logtrans.filter16mintot.grouped.csv", header=T)
means <- as.data.frame(matrix(nrow=nlevels(data$expgroup), ncol=0))
row.names(means) <- levels(data$expgroup)
for(i in 3:length(data)){
df <- aggregate( data[,i] ~ data$expgroup, data=data, mean )
names(df)[2] <- names(data)[i]
means <- as.data.frame(cbind( means, df[,2]))
names(means)[dim(means)[2]] <- names(data)[i]
}
means <- rbind(means, max=-1)
for(j in 1:length(means)){
means["max", j] <- max(means[,j])
}
means <- rbind(means, relabund=-1)
for(k in 1:length(means)){
means["relabund", k] <- (means[17,k])/1625
}
means <- rbind(means, percent=-1)
for(k in 1:length(means)){
means["percent", k] <- (means[18,k])*100
}
meanOTU <- means[,-1] #remove the nextDayCFU column
set <- NULL
set <- seq(0,3, by=0.01)
numOTUxThreshold <- NULL
numOTUxThreshold <- as.data.frame(cbind(numOTUxThreshold, set))
names(numOTUxThreshold)[1] <- "threshold"
numOTUxThreshold <- cbind(numOTUxThreshold, numOTU=NA)
for( i in 1:(length(set)) ) {
test <- meanOTU[ , meanOTU[19,] >= set[i] ]
#test2 <- sum( meanOTU[19,] >= set[i] )
numOTUxThreshold[i, 2] <- length(test)
}
plot(numOTUxThreshold$numOTU ~ numOTUxThreshold$threshold, xlab="Avg % RelAbund Threshold", ylab="# OTUs included")
abline(v=seq(0,3, by=.1), col="light gray")
abline(h=seq(1,300, by=10), col="light gray")
otusAtPercAbund <- function(percThresh, meanOTU){
perc <- meanOTU[ , meanOTU[19,] >= percThresh ]
otus <- names(perc)[-(length(perc))]
return(otus)
}
otus <- otusAtPercAbund(5, meanOTU)
rf.results<-RF.analysis(dataFile = "~/Desktop/mothur/abxD01/model/abxD01.final.an.unique_list.0.03.subsample.shared.toptitdel.noNewUntr.logtrans.filter16mintot.grouped.csv",
otus = otus, plot.title = paste("RF model, 1% cutoff relabund otus=", length(otus)))
perc<-5
otus <- otusAtPercAbund(perc, meanOTU)
rf.results<-RF.analysis(dataFile = "~/Desktop/mothur/abxD01/model/abxD01.final.an.unique_list.0.03.subsample.shared.toptitdel.noNewUntr.logtrans.filter16mintot.grouped.csv",
otus = otus, plot.title = paste0("RF model, ", perc, "% cutoff relabund otus=", length(otus)))
rf.results.perc5 <- rf.results
rf.results.perc5
perc<-1
otus <- otusAtPercAbund(perc, meanOTU)
rf.results<-RF.analysis(dataFile = "~/Desktop/mothur/abxD01/model/abxD01.final.an.unique_list.0.03.subsample.shared.toptitdel.noNewUntr.logtrans.filter16mintot.grouped.csv",
otus = otus, plot.title = paste0("RF model, ", perc, "% cutoff relabund otus=", length(otus)))
rf.results.perc1 <- rf.results
rf.results.perc1
perc<-1.5
otus <- otusAtPercAbund(perc, meanOTU)
rf.results<-RF.analysis(dataFile = "~/Desktop/mothur/abxD01/model/abxD01.final.an.unique_list.0.03.subsample.shared.toptitdel.noNewUntr.logtrans.filter16mintot.grouped.csv",
otus = otus, plot.title = paste0("RF model, ", perc, "% cutoff relabund otus=", length(otus)))
rf.results.perc1.5 <- rf.results
rf.results.perc1.5
perc<-3
otus <- otusAtPercAbund(perc, meanOTU)
rf.results<-RF.analysis(dataFile = "~/Desktop/mothur/abxD01/model/abxD01.final.an.unique_list.0.03.subsample.shared.toptitdel.noNewUntr.logtrans.filter16mintot.grouped.csv",
otus = otus, plot.title = paste0("RF model, ", perc, "% cutoff relabund otus=", length(otus)))
rf.results.perc3  <- rf.results
rf.results.perc3
perc<-2
otus <- otusAtPercAbund(perc, meanOTU)
rf.results<-RF.analysis(dataFile = "~/Desktop/mothur/abxD01/model/abxD01.final.an.unique_list.0.03.subsample.shared.toptitdel.noNewUntr.logtrans.filter16mintot.grouped.csv",
otus = otus, plot.title = paste0("RF model, ", perc, "% cutoff relabund otus=", length(otus)))
rf.results.perc2  <- rf.results
rf.results.perc2
perc<-2.5
otus <- otusAtPercAbund(perc, meanOTU)
rf.results<-RF.analysis(dataFile = "~/Desktop/mothur/abxD01/model/abxD01.final.an.unique_list.0.03.subsample.shared.toptitdel.noNewUntr.logtrans.filter16mintot.grouped.csv",
otus = otus, plot.title = paste0("RF model, ", perc, "% cutoff relabund otus=", length(otus)))
RF.validate <- function(data, iters){
numSamples <- dim(data)[1]
rsqs <- NULL
for(i in i:iters){
trainInd <- sample(1:(numSamples), (2/3*numSamples))
trainSet <- data[trainInd,]
testSet <- data[-trainInd,]
library(randomForest)
rf.trainSet <- randomForest(nextDayCFU~.,
data = trainSet[,-1],  outscale=TRUE,
importance=TRUE, proximity=TRUE,
keep.forest=TRUE
)
#plot(rf.trainSet)
#varImpPlot(rf.trainSet, type=1)
# plot.title <- "RF.model Validation: trained on 2/3 data, tested on 1/3"
rsqs <- c(rsqs,rf.predict(data=testSet, descr="rf.trainSet on Test Set Data", rf.model=rf.trainSet, title=plot.title, plotgraph = FALSE))
} #for(i in i:iters)
c(mean(rsqs), sd(rsqs))
#data.frame(mean=mean(rsqs), sd=sd(rsqs))
}
##########################################################################
# Inputs
#
# Returns
#
#
RF.analysis <- function(dataFile, otus, plot.title){
library(randomForest)
all <- read.csv(file=dataFile, header=T)
leng <- dim(all)[2]
cols<- NULL
for(i in 1:(length(otus))){
cols <-c(cols, which(names(all)==otus[i]))
}
cols <- c(which(names(all)=="Group"), which(names(all)=="nextDayCFU"), cols)
topdose <- all[1:99,cols]
toptit <- all[1:154,cols]
toptitdel <- all[,cols]
#fit the randomforest model
td.rf <- randomForest(nextDayCFU~.,
data = topdose[,-1],  outscale=TRUE,
importance=TRUE, proximity=TRUE,
keep.forest=TRUE, ntree=5000
) #assumes that the nexDayCFU column is right before the first Otu column
#plot(td.rf)
#what are the important variables (via permutation) #type 1 is mean decrease in accuracy, type 2 is mean decrease in node impurity
varImpPlot(td.rf, type=1)
#imp<-importance(td.rf)
#write.table(imp, file="~/Desktop/mothur/abxD01/rf/rf.topdose.avg0.01.txt", sep="\t", row.names=T, col.names=T)
# function to give me the prediction results on each data set
# td <- "~/Desktop/mothur/abxD01/rf/abxD01.final.an.unique_list.0.03.subsample.0.03.pick.shared.rf.topdose2.regression.logtrans.filter16mintot.csv"
# titr <- "~/Desktop/mothur/abxD01/rf/abxD01.final.an.unique_list.0.03.subsample.0.03.pick.shared.rf.newtitration.regression.logtrans.filter16mintot.noUntr.csv"
# delay <- "~/Desktop/mothur/abxD01/rf/abxD01.final.an.unique_list.0.03.subsample.0.03.pick.shared.rf.delay.regression.logtrans.filter16mintot.noUntr.csv"
td <- all[1:99,]
titr <- all[100:154,]
delay <- all[154:179,]
results <- data.frame(matrix(ncol=5, nrow=3))
row.names(results) <- c("topdose", "toptit", "toptitdel")
colnames(results) <- c("PercVarExpl","td", "titr", "delay", "withinValidate")
results[1,1] <- signif(td.rf$rsq[length(td.rf$rsq)],3)
results[1,2] <- signif(rf.predict(data=td, descr="td.rf on Topdose Data", rf.model=td.rf, title=plot.title),3)
results[1,3] <- signif(rf.predict(data=titr, descr="td.rf on Titration Data", rf.model=td.rf, title=plot.title),3)
results[1,4] <- signif(rf.predict(data=delay, descr="td.rf on Delay Data", rf.model=td.rf, title=plot.title),3)
results[1,5] <- signif(RF.validate(topdose, 100)[1],3)
######## Now with the toptit data
#fit the randomforest model
rf.toptit <- randomForest(nextDayCFU~.,
data = toptit[,-1],  outscale=TRUE,
importance=TRUE, proximity=TRUE,
keep.forest=TRUE, ntree=5000
)
#plot(rf.toptit)
#what are the important variables (via permutation) #type 1 is mean decrease in accuracy, type 2 is mean decrease in node impurity
varImpPlot(rf.toptit, type=1)
imp<-importance(rf.toptit)
#write.table(imp, file="~/Desktop/mothur/abxD01/rf/rf.toptit.avg0.01.txt", sep="\t", row.names=T, col.names=T)
results[2,1] <- signif(rf.toptit$rsq[length(rf.toptit$rsq)],3)
results[2,2] <- signif(rf.predict(data=td, descr="rf.toptit on Topdose Data", rf.model=rf.toptit, title=plot.title),3)
results[2,3] <- signif(rf.predict(data=titr, descr="rf.toptit on Titration Data", rf.model=rf.toptit, title=plot.title),3)
results[2,4] <- signif(rf.predict(data=delay, descr="rf.toptit on Delay Data", rf.model=rf.toptit, title=plot.title), 3)
results[2,5] <- signif(RF.validate(toptit, 100)[1],3)
######## Now with the toptitdel data
#fit the randomforest model
rf.toptitdel <- randomForest(nextDayCFU~.,
data = toptitdel[,-1],  outscale=TRUE,
importance=TRUE, proximity=TRUE,
keep.forest=TRUE, ntree=5000
)
#plot(rf.toptitdel)
#what are the important variables (via permutation) #type 1 is mean decrease in accuracy, type 2 is mean decrease in node impurity
varImpPlot(rf.toptitdel, type=1)
#imp<-importance(rf.toptitdel)
#write.table(imp, file="~/Desktop/mothur/abxD01/rf/rf.toptitdel.0.5p.txt", sep="\t", row.names=T, col.names=T)
results[3,1] <- signif(rf.toptitdel$rsq[length(rf.toptitdel$rsq)],3)
results[3,2] <- signif(rf.predict(data=td, descr="rf.toptitdel on Topdose Data", rf.model=rf.toptitdel, title=plot.title), 3)
results[3,3] <- signif(rf.predict(data=titr, descr="rf.toptitdel on Titration Data", rf.model=rf.toptitdel, title=plot.title), 3)
results[3,4] <- signif(rf.predict(data=delay, descr="rf.toptitdel on Delay Data", rf.model=rf.toptitdel, title=plot.title), 3)
results[3,5] <- signif(RF.validate(toptitdel, 100)[1],3)
return(results)
}
rf.results.perc2.5  <- rf.results
rf.results.perc2.5
rf.results.perc5
rf.results.perc3
clear
rf.results.perc2.5
rf.results.perc2
rf.results.perc1.5
rf.results.perc1
perc<-3
otus <- otusAtPercAbund(perc, meanOTU)
lengths(otus)
length(otus)
topdose<-read.csv("~/Desktop/mothur/abxD01/model/shared.topdose.noNewUntr.logtrans.0.75p.csv", header=T)
topdose<-topdose[,-1]
td.rf <- randomForest(nextDayCFU~.,
data = topdose,  outscale=TRUE,
importance=TRUE, proximity=TRUE,
keep.forest=TRUE, ntree=5000
)
plot(td.rf)
print(td.rf) # % Var explained: 88.06
varImpPlot(td.rf, type=1)
perc<-1
otus <- otusAtPercAbund(perc, meanOTU)
rf.results<-RF.analysis(dataFile = "~/Desktop/mothur/abxD01/model/abxD01.final.an.unique_list.0.03.subsample.shared.toptitdel.noNewUntr.logtrans.filter16mintot.grouped.csv",
otus = otus, plot.title = paste0("RF model, ", perc, "% cutoff relabund otus=", length(otus)))
rf.results<-RF.analysis(dataFile = "~/Desktop/mothur/abxD01/model/abxD01.final.an.unique_list.0.03.subsample.shared.toptitdel.noNewUntr.logtrans.filter16mintot.grouped.csv",
otus = otus, plot.title = paste0("RF model, ", perc, "% cutoff relabund otus=", length(otus)))
rf.results.perc1
dataFile = "~/Desktop/mothur/abxD01/model/abxD01.final.an.unique_list.0.03.subsample.shared.toptitdel.noNewUntr.logtrans.filter16mintot.grouped.csv
""
dataFile = "~/Desktop/mothur/abxD01/model/abxD01.final.an.unique_list.0.03.subsample.shared.toptitdel.noNewUntr.logtrans.filter16mintot.grouped.csv"
otus = otus
plot.title = paste0("RF model, ", perc, "% cutoff relabund otus=", length(otus))
library(randomForest)
all <- read.csv(file=dataFile, header=T)
leng <- dim(all)[2]
cols<- NULL
for(i in 1:(length(otus))){
cols <-c(cols, which(names(all)==otus[i]))
}
cols <- c(which(names(all)=="Group"), which(names(all)=="nextDayCFU"), cols)
topdose <- all[1:99,cols]
toptit <- all[1:154,cols]
toptitdel <- all[,cols]
td <- all[1:99,]
titr <- all[100:154,]
delay <- all[154:179,]
rf.toptitdel <- randomForest(nextDayCFU~.,
data = toptitdel[,-1],  outscale=TRUE,
importance=TRUE, proximity=TRUE,
keep.forest=TRUE, ntree=5000
)
varImpPlot(rf.toptitdel, type=1)
attributes(rf.toptitdel)
